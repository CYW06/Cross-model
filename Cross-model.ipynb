{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:35:47.946363800Z",
     "start_time": "2023-12-18T15:35:47.916203800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat,savemat\n",
    "import time\n",
    "import copy\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 构建图像 网络子网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5fc418721e6628c"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class ImageNN(nn.Module):\n",
    "    def __init__(self,input_dim=4096,output_dim=1024):\n",
    "        super(ImageNN,self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim,output_dim)\n",
    "    def forward(self,x):\n",
    "        return F.relu(self.denseL1(x))\n",
    "    \n",
    "class TextNN(nn.Module):\n",
    "    def __init__(self,input_dim=300,output_dim=1024):\n",
    "        super(TextNN,self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim,output_dim)\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.denseL1(x))\n",
    "        return out\n",
    "    \n",
    "class IDCM_NN(nn.Module):\n",
    "    def __init__(self,img_input_dim=4096, img_output_dim=2048,\n",
    "                 text_input_dim=1024, text_output_dim=2048, minus_one_dim=1024, output_dim=20):\n",
    "        super(IDCM_NN,self).__init__()\n",
    "        self.Img_net = ImageNN(img_input_dim, img_output_dim)\n",
    "        self.Text_net = TextNN(text_input_dim,text_output_dim)\n",
    "        self.Linear = nn.Linear(img_output_dim,minus_one_dim)\n",
    "        self.Linear1 = nn.Linear(text_output_dim, minus_one_dim)\n",
    "        self.Linear2 = nn.Linear(minus_one_dim,output_dim)\n",
    "        \n",
    "    def forward(self,img,txt):\n",
    "        view1_feature = self.Img_net(img)\n",
    "        view2_feature = self.Text_net(txt)\n",
    "        view1_feature = self.Linear(view1_feature)\n",
    "        view2_feature = self.Linear1(view2_feature)\n",
    "        \n",
    "        view1_predict = self.Linear2(view1_feature)\n",
    "        view2_predict = self.Linear2(view2_feature)\n",
    "        return view1_feature,view2_feature,view1_predict,view2_predict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:35:49.475692300Z",
     "start_time": "2023-12-18T15:35:49.460876600Z"
    }
   },
   "id": "c752272a944f5899"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 加载数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b9071866f26fb90"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            images,\n",
    "            texts,\n",
    "            labels):\n",
    "        self.images = images\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        return img,text,label\n",
    "    def __len__(self):\n",
    "        count = len(self.images)\n",
    "        assert len(self.texts)==len(self.labels)\n",
    "        return count\n",
    "def ind2vec(ind, N=None):\n",
    "    ind = np.asarray(ind)                                 \n",
    "    if N is None:\n",
    "        N = ind.max() + 1\n",
    "    return np.arange(N) == np.repeat(ind, N, axis=1)\n",
    "\n",
    "def get_loader(path,batch_size=32):\n",
    "    img_train = loadmat(path+'train_img.mat')['train_img']\n",
    "    img_test = loadmat(path+'test_img.mat')['test_img']\n",
    "    text_train = loadmat(path+\"train_txt.mat\")['train_txt']\n",
    "    text_test = loadmat(path + \"test_txt.mat\")['test_txt']\n",
    "    label_train = loadmat(path+\"train_img_lab.mat\")['train_img_lab']\n",
    "    label_test = loadmat(path + \"test_img_lab.mat\")['test_img_lab']\n",
    "    \n",
    "    label_train = ind2vec(label_train).astype(int)\n",
    "    label_test = ind2vec(label_test).astype(int)\n",
    "    \n",
    "    imgs = {'train': img_train, 'test': img_test}\n",
    "    texts = {'train': text_train, 'test': text_test}\n",
    "    labels = {'train': label_train, 'test': label_test}\n",
    "    dataset = {x: CustomDataSet(images=imgs[x], texts=texts[x], labels=labels[x])\n",
    "               for x in ['train', 'test']}\n",
    "\n",
    "    shuffle = {'train': False, 'test': False}\n",
    "\n",
    "    dataloader = {x: DataLoader(dataset[x], batch_size=batch_size,\n",
    "                                shuffle=shuffle[x], num_workers=0) for x in ['train', 'test']}\n",
    "\n",
    "   \n",
    "   # 获取图像和文本的维度以及类别数量\n",
    "    img_dim = img_train.shape[1]\n",
    "    text_dim = text_train.shape[1]\n",
    "    num_class = label_train.shape[1]\n",
    "\n",
    "    \n",
    "    # 数据参数字典\n",
    "    input_data_par = {}\n",
    "    input_data_par['img_test'] = img_test\n",
    "    input_data_par['text_test'] = text_test\n",
    "    input_data_par['label_test'] = label_test\n",
    "    input_data_par['img_train'] = img_train\n",
    "    input_data_par['text_train'] = text_train\n",
    "    input_data_par['label_train'] = label_train\n",
    "    input_data_par['img_dim'] = img_dim\n",
    "    input_data_par['text_dim'] = text_dim\n",
    "    input_data_par['num_class'] = num_class\n",
    "\n",
    "    return dataloader, input_data_par"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:37:55.657330200Z",
     "start_time": "2023-12-18T15:37:55.641059900Z"
    }
   },
   "id": "b48a925487326379"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 计算mAP(平均查准率均值)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a5ae6e4f58d22b"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def fx_calc_map_label(image, text, label, k=0, dist_method='COS'):\n",
    "    if dist_method == 'L2':\n",
    "        dist = scipy.spatial.distance.cdist(image, text, 'euclidean')\n",
    "    elif dist_method == 'COS':\n",
    "        dist = scipy.spatial.distance.cdist(image, text, 'cosine')\n",
    "    ord = dist.argsort()\n",
    "    numcases = dist.shape[0]\n",
    "    if k == 0:\n",
    "        k = numcases\n",
    "    res = []\n",
    "    for i in range(numcases):\n",
    "        order = ord[i]\n",
    "        p = 0.0\n",
    "        r = 0.0\n",
    "        for j in range(k):\n",
    "            if label[i] == label[order[j]]:\n",
    "                r += 1\n",
    "                p += (r / (j + 1))\n",
    "        if r > 0:\n",
    "            res += [p / r]\n",
    "        else:\n",
    "            res += [0]\n",
    "    return np.mean(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:37:57.088962600Z",
     "start_time": "2023-12-18T15:37:57.081722200Z"
    }
   },
   "id": "82201fea363e622f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 损失函数构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4f738f21661ea9"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def cos_distance(source, target):\n",
    "    cos_sim = F.cosine_similarity(source.unsqueeze(0), target,dim=-1)\n",
    "    distance = torch.clamp(1-cos_sim,0)\n",
    "    return distance\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, source, s_labels, target=None, t_labels=None, margin=0):\n",
    "        if target is None:\n",
    "            target = source\n",
    "        if t_labels is None:\n",
    "            t_labels = s_labels\n",
    "\n",
    "        pairwise_dist = cos_distance(source, target)\n",
    "\n",
    "        anchor_positive_dist = pairwise_dist.unsqueeze(2)\n",
    "        anchor_negative_dist = pairwise_dist.unsqueeze(1)\n",
    "        triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
    "        triplet_loss = triplet_loss.clamp(0)\n",
    "\n",
    "        valid_triplets = triplet_loss.gt(1e-16).float()\n",
    "        num_positive_triplets = valid_triplets.sum()\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            triplet_loss = triplet_loss.sum() / (num_positive_triplets + 1e-16)\n",
    "        elif self.reduction == 'sum':\n",
    "            triplet_loss = triplet_loss.sum()\n",
    "\n",
    "        return triplet_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:37:58.487712900Z",
     "start_time": "2023-12-18T15:37:58.477696300Z"
    }
   },
   "id": "d5723cfe2a675820"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def calc_loss(view1_feature, view2_feature, view1_predict, view2_predict, labels_1, labels_2, alpha, beta,gamma):\n",
    "#三元组损失\n",
    "    tri_loss = TripletLoss(reduction='mean')\n",
    "    tri_i2t = tri_loss(view1_feature, labels_1.float(), target=view2_feature, margin=0.1)\n",
    "    tri_t2i = tri_loss(view2_feature, labels_2.float(), target=view1_feature, margin=0.1)\n",
    "    cos_tri = tri_i2t + tri_t2i\n",
    "#计算图文特征矩阵的距离损失，即差的F范数 \n",
    "    floss = ((view1_feature - view2_feature)**2).sum(1).sqrt().mean()\n",
    "#计算标签矩阵的损失\n",
    "    lloss = ((view1_predict-labels_1.float())**2).sum(1).sqrt().mean() + ((view2_predict-labels_2.float())**2).sum(1).sqrt().mean()\n",
    "#损失求和，并给出超参数\n",
    "    im_loss = alpha * cos_tri + beta*floss+ gamma*lloss\n",
    "\n",
    "    return im_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:37:59.181772500Z",
     "start_time": "2023-12-18T15:37:59.171782300Z"
    }
   },
   "id": "88ece2a916150b04"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def train_model(model, data_loaders, optimizer, alpha, beta,gamma, num_epochs):\n",
    "    since = time.time()\n",
    "    test_img_acc_history = []\n",
    "    test_txt_acc_history = []\n",
    "    epoch_loss_history =[]\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects_img = 0\n",
    "            running_corrects_txt = 0\n",
    "            for imgs, txts, labels in data_loaders[phase]:\n",
    "                if torch.sum(imgs != imgs)>1 or torch.sum(txts != txts)>1:\n",
    "                    print(\"Data contains Nan.\")\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                  \n",
    "                    if torch.cuda.is_available():\n",
    "                        imgs = imgs.cuda()\n",
    "                        txts = txts.cuda()\n",
    "                        labels = labels.cuda()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    view1_feature, view2_feature, view1_predict, view2_predict = model(imgs, txts)\n",
    "\n",
    "                    loss = calc_loss(view1_feature, view2_feature, view1_predict,\n",
    "                                     view2_predict, labels, labels, alpha, beta,gamma)\n",
    "\n",
    "                    img_preds = view1_predict\n",
    "                    txt_preds = view2_predict\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_corrects_img += torch.sum(torch.argmax(img_preds, dim=1) == torch.argmax(labels, dim=1))\n",
    "                running_corrects_txt += torch.sum(torch.argmax(txt_preds, dim=1) == torch.argmax(labels, dim=1))\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loaders[phase].dataset)\n",
    "            t_imgs, t_txts, t_labels = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for imgs, txts, labels in data_loaders['test']:\n",
    "                    if torch.cuda.is_available():\n",
    "                            imgs = imgs.cuda()\n",
    "                            txts = txts.cuda()\n",
    "                            labels = labels.cuda()\n",
    "                    t_view1_feature, t_view2_feature, _, _ = model(imgs, txts)\n",
    "                    t_imgs.append(t_view1_feature.cpu().numpy())\n",
    "                    t_txts.append(t_view2_feature.cpu().numpy())\n",
    "                    t_labels.append(labels.cpu().numpy())\n",
    "            t_imgs = np.concatenate(t_imgs)\n",
    "            t_txts = np.concatenate(t_txts)\n",
    "            t_labels = np.concatenate(t_labels).argmax(1)\n",
    "            img2text = fx_calc_map_label(t_imgs, t_txts, t_labels)\n",
    "            txt2img = fx_calc_map_label(t_txts, t_imgs, t_labels)\n",
    "\n",
    "            print('{} Loss: {:.4f} Img2Txt: {:.4f}  Txt2Img: {:.4f}'.format(phase, epoch_loss, img2text, txt2img))\n",
    "\n",
    "            if phase == 'test' and (img2text + txt2img) / 2. > best_acc:\n",
    "                best_acc = (img2text + txt2img) / 2.\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'test':\n",
    "                test_img_acc_history.append(img2text)\n",
    "                test_txt_acc_history.append(txt2img)\n",
    "                epoch_loss_history.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best average ACC: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, test_img_acc_history, test_txt_acc_history, epoch_loss_history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:37:59.733541100Z",
     "start_time": "2023-12-18T15:37:59.730033100Z"
    }
   },
   "id": "60b81bfb1c3b1a3b"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据\n",
      "开始训练\n",
      "Epoch 1/130\n",
      "--------------------\n",
      "train Loss: 0.2731 Img2Txt: 0.2553  Txt2Img: 0.2569\n",
      "test Loss: 0.2252 Img2Txt: 0.2553  Txt2Img: 0.2569\n",
      "Epoch 2/130\n",
      "--------------------\n",
      "train Loss: 0.2252 Img2Txt: 0.4425  Txt2Img: 0.4915\n",
      "test Loss: 0.1978 Img2Txt: 0.4425  Txt2Img: 0.4915\n",
      "Epoch 3/130\n",
      "--------------------\n",
      "train Loss: 0.2006 Img2Txt: 0.5570  Txt2Img: 0.5606\n",
      "test Loss: 0.1793 Img2Txt: 0.5570  Txt2Img: 0.5606\n",
      "Epoch 4/130\n",
      "--------------------\n",
      "train Loss: 0.1796 Img2Txt: 0.5993  Txt2Img: 0.6023\n",
      "test Loss: 0.1660 Img2Txt: 0.5993  Txt2Img: 0.6023\n",
      "Epoch 5/130\n",
      "--------------------\n",
      "train Loss: 0.1616 Img2Txt: 0.6184  Txt2Img: 0.6386\n",
      "test Loss: 0.1581 Img2Txt: 0.6184  Txt2Img: 0.6386\n",
      "Epoch 6/130\n",
      "--------------------\n",
      "train Loss: 0.1489 Img2Txt: 0.6291  Txt2Img: 0.6632\n",
      "test Loss: 0.1559 Img2Txt: 0.6291  Txt2Img: 0.6632\n",
      "Epoch 7/130\n",
      "--------------------\n",
      "train Loss: 0.1437 Img2Txt: 0.6311  Txt2Img: 0.6736\n",
      "test Loss: 0.1537 Img2Txt: 0.6311  Txt2Img: 0.6736\n",
      "Epoch 8/130\n",
      "--------------------\n",
      "train Loss: 0.1365 Img2Txt: 0.6521  Txt2Img: 0.6892\n",
      "test Loss: 0.1555 Img2Txt: 0.6521  Txt2Img: 0.6892\n",
      "Epoch 9/130\n",
      "--------------------\n",
      "train Loss: 0.1358 Img2Txt: 0.6453  Txt2Img: 0.6830\n",
      "test Loss: 0.1519 Img2Txt: 0.6453  Txt2Img: 0.6830\n",
      "Epoch 10/130\n",
      "--------------------\n",
      "train Loss: 0.1306 Img2Txt: 0.6609  Txt2Img: 0.6951\n",
      "test Loss: 0.1537 Img2Txt: 0.6609  Txt2Img: 0.6951\n",
      "Epoch 11/130\n",
      "--------------------\n",
      "train Loss: 0.1261 Img2Txt: 0.6691  Txt2Img: 0.7006\n",
      "test Loss: 0.1478 Img2Txt: 0.6691  Txt2Img: 0.7006\n",
      "Epoch 12/130\n",
      "--------------------\n",
      "train Loss: 0.1230 Img2Txt: 0.6639  Txt2Img: 0.7176\n",
      "test Loss: 0.1510 Img2Txt: 0.6639  Txt2Img: 0.7176\n",
      "Epoch 13/130\n",
      "--------------------\n",
      "train Loss: 0.1187 Img2Txt: 0.6725  Txt2Img: 0.7034\n",
      "test Loss: 0.1547 Img2Txt: 0.6725  Txt2Img: 0.7034\n",
      "Epoch 14/130\n",
      "--------------------\n",
      "train Loss: 0.1224 Img2Txt: 0.6777  Txt2Img: 0.7182\n",
      "test Loss: 0.1470 Img2Txt: 0.6777  Txt2Img: 0.7182\n",
      "Epoch 15/130\n",
      "--------------------\n",
      "train Loss: 0.1155 Img2Txt: 0.6802  Txt2Img: 0.7080\n",
      "test Loss: 0.1462 Img2Txt: 0.6802  Txt2Img: 0.7080\n",
      "Epoch 16/130\n",
      "--------------------\n",
      "train Loss: 0.1118 Img2Txt: 0.6751  Txt2Img: 0.7001\n",
      "test Loss: 0.1459 Img2Txt: 0.6751  Txt2Img: 0.7001\n",
      "Epoch 17/130\n",
      "--------------------\n",
      "train Loss: 0.1102 Img2Txt: 0.6701  Txt2Img: 0.7077\n",
      "test Loss: 0.1434 Img2Txt: 0.6701  Txt2Img: 0.7077\n",
      "Epoch 18/130\n",
      "--------------------\n",
      "train Loss: 0.1055 Img2Txt: 0.6661  Txt2Img: 0.7110\n",
      "test Loss: 0.1444 Img2Txt: 0.6661  Txt2Img: 0.7110\n",
      "Epoch 19/130\n",
      "--------------------\n",
      "train Loss: 0.1070 Img2Txt: 0.6625  Txt2Img: 0.7011\n",
      "test Loss: 0.1458 Img2Txt: 0.6625  Txt2Img: 0.7011\n",
      "Epoch 20/130\n",
      "--------------------\n",
      "train Loss: 0.1043 Img2Txt: 0.6995  Txt2Img: 0.7175\n",
      "test Loss: 0.1423 Img2Txt: 0.6995  Txt2Img: 0.7175\n",
      "Epoch 21/130\n",
      "--------------------\n",
      "train Loss: 0.1009 Img2Txt: 0.6822  Txt2Img: 0.7017\n",
      "test Loss: 0.1413 Img2Txt: 0.6822  Txt2Img: 0.7017\n",
      "Epoch 22/130\n",
      "--------------------\n",
      "train Loss: 0.0988 Img2Txt: 0.6854  Txt2Img: 0.7145\n",
      "test Loss: 0.1376 Img2Txt: 0.6854  Txt2Img: 0.7145\n",
      "Epoch 23/130\n",
      "--------------------\n",
      "train Loss: 0.0986 Img2Txt: 0.6602  Txt2Img: 0.7048\n",
      "test Loss: 0.1401 Img2Txt: 0.6602  Txt2Img: 0.7048\n",
      "Epoch 24/130\n",
      "--------------------\n",
      "train Loss: 0.0941 Img2Txt: 0.6950  Txt2Img: 0.7214\n",
      "test Loss: 0.1404 Img2Txt: 0.6950  Txt2Img: 0.7214\n",
      "Epoch 25/130\n",
      "--------------------\n",
      "train Loss: 0.0940 Img2Txt: 0.6722  Txt2Img: 0.6977\n",
      "test Loss: 0.1415 Img2Txt: 0.6722  Txt2Img: 0.6977\n",
      "Epoch 26/130\n",
      "--------------------\n",
      "train Loss: 0.0950 Img2Txt: 0.6873  Txt2Img: 0.7147\n",
      "test Loss: 0.1397 Img2Txt: 0.6873  Txt2Img: 0.7147\n",
      "Epoch 27/130\n",
      "--------------------\n",
      "train Loss: 0.0941 Img2Txt: 0.6920  Txt2Img: 0.7086\n",
      "test Loss: 0.1375 Img2Txt: 0.6920  Txt2Img: 0.7086\n",
      "Epoch 28/130\n",
      "--------------------\n",
      "train Loss: 0.0916 Img2Txt: 0.6747  Txt2Img: 0.7040\n",
      "test Loss: 0.1380 Img2Txt: 0.6747  Txt2Img: 0.7040\n",
      "Epoch 29/130\n",
      "--------------------\n",
      "train Loss: 0.0899 Img2Txt: 0.6855  Txt2Img: 0.7070\n",
      "test Loss: 0.1410 Img2Txt: 0.6855  Txt2Img: 0.7070\n",
      "Epoch 30/130\n",
      "--------------------\n",
      "train Loss: 0.0901 Img2Txt: 0.6686  Txt2Img: 0.7015\n",
      "test Loss: 0.1348 Img2Txt: 0.6686  Txt2Img: 0.7015\n",
      "Epoch 31/130\n",
      "--------------------\n",
      "train Loss: 0.0891 Img2Txt: 0.6783  Txt2Img: 0.6998\n",
      "test Loss: 0.1374 Img2Txt: 0.6783  Txt2Img: 0.6998\n",
      "Epoch 32/130\n",
      "--------------------\n",
      "train Loss: 0.0899 Img2Txt: 0.6980  Txt2Img: 0.7137\n",
      "test Loss: 0.1365 Img2Txt: 0.6980  Txt2Img: 0.7137\n",
      "Epoch 33/130\n",
      "--------------------\n",
      "train Loss: 0.0871 Img2Txt: 0.6701  Txt2Img: 0.6992\n",
      "test Loss: 0.1362 Img2Txt: 0.6701  Txt2Img: 0.6992\n",
      "Epoch 34/130\n",
      "--------------------\n",
      "train Loss: 0.0866 Img2Txt: 0.6656  Txt2Img: 0.6984\n",
      "test Loss: 0.1379 Img2Txt: 0.6656  Txt2Img: 0.6984\n",
      "Epoch 35/130\n",
      "--------------------\n",
      "train Loss: 0.0863 Img2Txt: 0.6845  Txt2Img: 0.7054\n",
      "test Loss: 0.1335 Img2Txt: 0.6845  Txt2Img: 0.7054\n",
      "Epoch 36/130\n",
      "--------------------\n",
      "train Loss: 0.0824 Img2Txt: 0.6421  Txt2Img: 0.6916\n",
      "test Loss: 0.1389 Img2Txt: 0.6421  Txt2Img: 0.6916\n",
      "Epoch 37/130\n",
      "--------------------\n",
      "train Loss: 0.0866 Img2Txt: 0.6796  Txt2Img: 0.7044\n",
      "test Loss: 0.1353 Img2Txt: 0.6796  Txt2Img: 0.7044\n",
      "Epoch 38/130\n",
      "--------------------\n",
      "train Loss: 0.0853 Img2Txt: 0.6749  Txt2Img: 0.7018\n",
      "test Loss: 0.1354 Img2Txt: 0.6749  Txt2Img: 0.7018\n",
      "Epoch 39/130\n",
      "--------------------\n",
      "train Loss: 0.0801 Img2Txt: 0.6530  Txt2Img: 0.6901\n",
      "test Loss: 0.1357 Img2Txt: 0.6530  Txt2Img: 0.6901\n",
      "Epoch 40/130\n",
      "--------------------\n",
      "train Loss: 0.0834 Img2Txt: 0.6690  Txt2Img: 0.6944\n",
      "test Loss: 0.1360 Img2Txt: 0.6690  Txt2Img: 0.6944\n",
      "Epoch 41/130\n",
      "--------------------\n",
      "train Loss: 0.0807 Img2Txt: 0.6751  Txt2Img: 0.7035\n",
      "test Loss: 0.1336 Img2Txt: 0.6751  Txt2Img: 0.7035\n",
      "Epoch 42/130\n",
      "--------------------\n",
      "train Loss: 0.0801 Img2Txt: 0.6662  Txt2Img: 0.6940\n",
      "test Loss: 0.1351 Img2Txt: 0.6662  Txt2Img: 0.6940\n",
      "Epoch 43/130\n",
      "--------------------\n",
      "train Loss: 0.0816 Img2Txt: 0.6879  Txt2Img: 0.7081\n",
      "test Loss: 0.1331 Img2Txt: 0.6879  Txt2Img: 0.7081\n",
      "Epoch 44/130\n",
      "--------------------\n",
      "train Loss: 0.0765 Img2Txt: 0.6231  Txt2Img: 0.6816\n",
      "test Loss: 0.1353 Img2Txt: 0.6231  Txt2Img: 0.6816\n",
      "Epoch 45/130\n",
      "--------------------\n",
      "train Loss: 0.0821 Img2Txt: 0.6747  Txt2Img: 0.7002\n",
      "test Loss: 0.1347 Img2Txt: 0.6747  Txt2Img: 0.7002\n",
      "Epoch 46/130\n",
      "--------------------\n",
      "train Loss: 0.0774 Img2Txt: 0.6717  Txt2Img: 0.6955\n",
      "test Loss: 0.1330 Img2Txt: 0.6717  Txt2Img: 0.6955\n",
      "Epoch 47/130\n",
      "--------------------\n",
      "train Loss: 0.0800 Img2Txt: 0.6445  Txt2Img: 0.6971\n",
      "test Loss: 0.1347 Img2Txt: 0.6445  Txt2Img: 0.6971\n",
      "Epoch 48/130\n",
      "--------------------\n",
      "train Loss: 0.0791 Img2Txt: 0.6666  Txt2Img: 0.6973\n",
      "test Loss: 0.1323 Img2Txt: 0.6666  Txt2Img: 0.6973\n",
      "Epoch 49/130\n",
      "--------------------\n",
      "train Loss: 0.0766 Img2Txt: 0.6562  Txt2Img: 0.6990\n",
      "test Loss: 0.1332 Img2Txt: 0.6562  Txt2Img: 0.6990\n",
      "Epoch 50/130\n",
      "--------------------\n",
      "train Loss: 0.0771 Img2Txt: 0.6484  Txt2Img: 0.6903\n",
      "test Loss: 0.1334 Img2Txt: 0.6484  Txt2Img: 0.6903\n",
      "Epoch 51/130\n",
      "--------------------\n",
      "train Loss: 0.0750 Img2Txt: 0.6711  Txt2Img: 0.7002\n",
      "test Loss: 0.1308 Img2Txt: 0.6711  Txt2Img: 0.7002\n",
      "Epoch 52/130\n",
      "--------------------\n",
      "train Loss: 0.0740 Img2Txt: 0.6855  Txt2Img: 0.7053\n",
      "test Loss: 0.1332 Img2Txt: 0.6855  Txt2Img: 0.7053\n",
      "Epoch 53/130\n",
      "--------------------\n",
      "train Loss: 0.0757 Img2Txt: 0.6500  Txt2Img: 0.6970\n",
      "test Loss: 0.1340 Img2Txt: 0.6500  Txt2Img: 0.6970\n",
      "Epoch 54/130\n",
      "--------------------\n",
      "train Loss: 0.0777 Img2Txt: 0.6698  Txt2Img: 0.6904\n",
      "test Loss: 0.1290 Img2Txt: 0.6698  Txt2Img: 0.6904\n",
      "Epoch 55/130\n",
      "--------------------\n",
      "train Loss: 0.0705 Img2Txt: 0.6809  Txt2Img: 0.7069\n",
      "test Loss: 0.1353 Img2Txt: 0.6809  Txt2Img: 0.7069\n",
      "Epoch 56/130\n",
      "--------------------\n",
      "train Loss: 0.0754 Img2Txt: 0.6824  Txt2Img: 0.7018\n",
      "test Loss: 0.1292 Img2Txt: 0.6824  Txt2Img: 0.7018\n",
      "Epoch 57/130\n",
      "--------------------\n",
      "train Loss: 0.0724 Img2Txt: 0.6744  Txt2Img: 0.7044\n",
      "test Loss: 0.1311 Img2Txt: 0.6744  Txt2Img: 0.7044\n",
      "Epoch 58/130\n",
      "--------------------\n",
      "train Loss: 0.0714 Img2Txt: 0.6623  Txt2Img: 0.6885\n",
      "test Loss: 0.1309 Img2Txt: 0.6623  Txt2Img: 0.6885\n",
      "Epoch 59/130\n",
      "--------------------\n",
      "train Loss: 0.0712 Img2Txt: 0.6514  Txt2Img: 0.6914\n",
      "test Loss: 0.1329 Img2Txt: 0.6514  Txt2Img: 0.6914\n",
      "Epoch 60/130\n",
      "--------------------\n",
      "train Loss: 0.0722 Img2Txt: 0.6893  Txt2Img: 0.6997\n",
      "test Loss: 0.1320 Img2Txt: 0.6893  Txt2Img: 0.6997\n",
      "Epoch 61/130\n",
      "--------------------\n",
      "train Loss: 0.0746 Img2Txt: 0.6793  Txt2Img: 0.7024\n",
      "test Loss: 0.1311 Img2Txt: 0.6793  Txt2Img: 0.7024\n",
      "Epoch 62/130\n",
      "--------------------\n",
      "train Loss: 0.0694 Img2Txt: 0.6524  Txt2Img: 0.6839\n",
      "test Loss: 0.1290 Img2Txt: 0.6524  Txt2Img: 0.6839\n",
      "Epoch 63/130\n",
      "--------------------\n",
      "train Loss: 0.0707 Img2Txt: 0.6786  Txt2Img: 0.7010\n",
      "test Loss: 0.1301 Img2Txt: 0.6786  Txt2Img: 0.7010\n",
      "Epoch 64/130\n",
      "--------------------\n",
      "train Loss: 0.0708 Img2Txt: 0.6398  Txt2Img: 0.6822\n",
      "test Loss: 0.1326 Img2Txt: 0.6398  Txt2Img: 0.6822\n",
      "Epoch 65/130\n",
      "--------------------\n",
      "train Loss: 0.0708 Img2Txt: 0.6858  Txt2Img: 0.7004\n",
      "test Loss: 0.1292 Img2Txt: 0.6858  Txt2Img: 0.7004\n",
      "Epoch 66/130\n",
      "--------------------\n",
      "train Loss: 0.0737 Img2Txt: 0.6437  Txt2Img: 0.6912\n",
      "test Loss: 0.1302 Img2Txt: 0.6437  Txt2Img: 0.6912\n",
      "Epoch 67/130\n",
      "--------------------\n",
      "train Loss: 0.0711 Img2Txt: 0.6878  Txt2Img: 0.6957\n",
      "test Loss: 0.1300 Img2Txt: 0.6878  Txt2Img: 0.6957\n",
      "Epoch 68/130\n",
      "--------------------\n",
      "train Loss: 0.0679 Img2Txt: 0.6153  Txt2Img: 0.6800\n",
      "test Loss: 0.1332 Img2Txt: 0.6153  Txt2Img: 0.6800\n",
      "Epoch 69/130\n",
      "--------------------\n",
      "train Loss: 0.0763 Img2Txt: 0.6998  Txt2Img: 0.7056\n",
      "test Loss: 0.1284 Img2Txt: 0.6998  Txt2Img: 0.7056\n",
      "Epoch 70/130\n",
      "--------------------\n",
      "train Loss: 0.0654 Img2Txt: 0.6549  Txt2Img: 0.6966\n",
      "test Loss: 0.1297 Img2Txt: 0.6549  Txt2Img: 0.6966\n",
      "Epoch 71/130\n",
      "--------------------\n",
      "train Loss: 0.0700 Img2Txt: 0.6670  Txt2Img: 0.6931\n",
      "test Loss: 0.1308 Img2Txt: 0.6670  Txt2Img: 0.6931\n",
      "Epoch 72/130\n",
      "--------------------\n",
      "train Loss: 0.0678 Img2Txt: 0.6598  Txt2Img: 0.6906\n",
      "test Loss: 0.1285 Img2Txt: 0.6598  Txt2Img: 0.6906\n",
      "Epoch 73/130\n",
      "--------------------\n",
      "train Loss: 0.0666 Img2Txt: 0.6878  Txt2Img: 0.6946\n",
      "test Loss: 0.1272 Img2Txt: 0.6878  Txt2Img: 0.6946\n",
      "Epoch 74/130\n",
      "--------------------\n",
      "train Loss: 0.0608 Img2Txt: 0.6340  Txt2Img: 0.6942\n",
      "test Loss: 0.1299 Img2Txt: 0.6340  Txt2Img: 0.6942\n",
      "Epoch 75/130\n",
      "--------------------\n",
      "train Loss: 0.0703 Img2Txt: 0.6853  Txt2Img: 0.6925\n",
      "test Loss: 0.1289 Img2Txt: 0.6853  Txt2Img: 0.6925\n",
      "Epoch 76/130\n",
      "--------------------\n",
      "train Loss: 0.0652 Img2Txt: 0.6661  Txt2Img: 0.6954\n",
      "test Loss: 0.1291 Img2Txt: 0.6661  Txt2Img: 0.6954\n",
      "Epoch 77/130\n",
      "--------------------\n",
      "train Loss: 0.0670 Img2Txt: 0.6900  Txt2Img: 0.7043\n",
      "test Loss: 0.1273 Img2Txt: 0.6900  Txt2Img: 0.7043\n",
      "Epoch 78/130\n",
      "--------------------\n",
      "train Loss: 0.0610 Img2Txt: 0.6391  Txt2Img: 0.6854\n",
      "test Loss: 0.1284 Img2Txt: 0.6391  Txt2Img: 0.6854\n",
      "Epoch 79/130\n",
      "--------------------\n",
      "train Loss: 0.0696 Img2Txt: 0.6718  Txt2Img: 0.6942\n",
      "test Loss: 0.1302 Img2Txt: 0.6718  Txt2Img: 0.6942\n",
      "Epoch 80/130\n",
      "--------------------\n",
      "train Loss: 0.0654 Img2Txt: 0.6663  Txt2Img: 0.6865\n",
      "test Loss: 0.1273 Img2Txt: 0.6663  Txt2Img: 0.6865\n",
      "Epoch 81/130\n",
      "--------------------\n",
      "train Loss: 0.0632 Img2Txt: 0.6445  Txt2Img: 0.6970\n",
      "test Loss: 0.1306 Img2Txt: 0.6445  Txt2Img: 0.6970\n",
      "Epoch 82/130\n",
      "--------------------\n",
      "train Loss: 0.0622 Img2Txt: 0.6737  Txt2Img: 0.6992\n",
      "test Loss: 0.1263 Img2Txt: 0.6737  Txt2Img: 0.6992\n",
      "Epoch 83/130\n",
      "--------------------\n",
      "train Loss: 0.0662 Img2Txt: 0.6440  Txt2Img: 0.6807\n",
      "test Loss: 0.1313 Img2Txt: 0.6440  Txt2Img: 0.6807\n",
      "Epoch 84/130\n",
      "--------------------\n",
      "train Loss: 0.0648 Img2Txt: 0.6838  Txt2Img: 0.6949\n",
      "test Loss: 0.1289 Img2Txt: 0.6838  Txt2Img: 0.6949\n",
      "Epoch 85/130\n",
      "--------------------\n",
      "train Loss: 0.0635 Img2Txt: 0.6847  Txt2Img: 0.6954\n",
      "test Loss: 0.1282 Img2Txt: 0.6847  Txt2Img: 0.6954\n",
      "Epoch 86/130\n",
      "--------------------\n",
      "train Loss: 0.0636 Img2Txt: 0.6665  Txt2Img: 0.6967\n",
      "test Loss: 0.1279 Img2Txt: 0.6665  Txt2Img: 0.6967\n",
      "Epoch 87/130\n",
      "--------------------\n",
      "train Loss: 0.0626 Img2Txt: 0.6698  Txt2Img: 0.6880\n",
      "test Loss: 0.1277 Img2Txt: 0.6698  Txt2Img: 0.6880\n",
      "Epoch 88/130\n",
      "--------------------\n",
      "train Loss: 0.0663 Img2Txt: 0.6776  Txt2Img: 0.6940\n",
      "test Loss: 0.1291 Img2Txt: 0.6776  Txt2Img: 0.6940\n",
      "Epoch 89/130\n",
      "--------------------\n",
      "train Loss: 0.0631 Img2Txt: 0.6518  Txt2Img: 0.6975\n",
      "test Loss: 0.1266 Img2Txt: 0.6518  Txt2Img: 0.6975\n",
      "Epoch 90/130\n",
      "--------------------\n",
      "train Loss: 0.0672 Img2Txt: 0.6762  Txt2Img: 0.6961\n",
      "test Loss: 0.1284 Img2Txt: 0.6762  Txt2Img: 0.6961\n",
      "Epoch 91/130\n",
      "--------------------\n",
      "train Loss: 0.0611 Img2Txt: 0.6513  Txt2Img: 0.6969\n",
      "test Loss: 0.1293 Img2Txt: 0.6513  Txt2Img: 0.6969\n",
      "Epoch 92/130\n",
      "--------------------\n",
      "train Loss: 0.0630 Img2Txt: 0.6766  Txt2Img: 0.6949\n",
      "test Loss: 0.1246 Img2Txt: 0.6766  Txt2Img: 0.6949\n",
      "Epoch 93/130\n",
      "--------------------\n",
      "train Loss: 0.0575 Img2Txt: 0.6294  Txt2Img: 0.6898\n",
      "test Loss: 0.1314 Img2Txt: 0.6294  Txt2Img: 0.6898\n",
      "Epoch 94/130\n",
      "--------------------\n",
      "train Loss: 0.0671 Img2Txt: 0.6853  Txt2Img: 0.6935\n",
      "test Loss: 0.1251 Img2Txt: 0.6853  Txt2Img: 0.6935\n",
      "Epoch 95/130\n",
      "--------------------\n",
      "train Loss: 0.0579 Img2Txt: 0.6848  Txt2Img: 0.6998\n",
      "test Loss: 0.1289 Img2Txt: 0.6848  Txt2Img: 0.6998\n",
      "Epoch 96/130\n",
      "--------------------\n",
      "train Loss: 0.0631 Img2Txt: 0.6628  Txt2Img: 0.6896\n",
      "test Loss: 0.1252 Img2Txt: 0.6628  Txt2Img: 0.6896\n",
      "Epoch 97/130\n",
      "--------------------\n",
      "train Loss: 0.0602 Img2Txt: 0.6620  Txt2Img: 0.6971\n",
      "test Loss: 0.1300 Img2Txt: 0.6620  Txt2Img: 0.6971\n",
      "Epoch 98/130\n",
      "--------------------\n",
      "train Loss: 0.0652 Img2Txt: 0.6520  Txt2Img: 0.6882\n",
      "test Loss: 0.1270 Img2Txt: 0.6520  Txt2Img: 0.6882\n",
      "Epoch 99/130\n",
      "--------------------\n",
      "train Loss: 0.0567 Img2Txt: 0.6920  Txt2Img: 0.6968\n",
      "test Loss: 0.1267 Img2Txt: 0.6920  Txt2Img: 0.6968\n",
      "Epoch 100/130\n",
      "--------------------\n",
      "train Loss: 0.0626 Img2Txt: 0.6700  Txt2Img: 0.6874\n",
      "test Loss: 0.1275 Img2Txt: 0.6700  Txt2Img: 0.6874\n",
      "Epoch 101/130\n",
      "--------------------\n",
      "train Loss: 0.0599 Img2Txt: 0.6587  Txt2Img: 0.6913\n",
      "test Loss: 0.1299 Img2Txt: 0.6587  Txt2Img: 0.6913\n",
      "Epoch 102/130\n",
      "--------------------\n",
      "train Loss: 0.0661 Img2Txt: 0.6550  Txt2Img: 0.6876\n",
      "test Loss: 0.1274 Img2Txt: 0.6550  Txt2Img: 0.6876\n",
      "Epoch 103/130\n",
      "--------------------\n",
      "train Loss: 0.0572 Img2Txt: 0.6826  Txt2Img: 0.6973\n",
      "test Loss: 0.1269 Img2Txt: 0.6826  Txt2Img: 0.6973\n",
      "Epoch 104/130\n",
      "--------------------\n",
      "train Loss: 0.0645 Img2Txt: 0.6650  Txt2Img: 0.6851\n",
      "test Loss: 0.1275 Img2Txt: 0.6650  Txt2Img: 0.6851\n",
      "Epoch 105/130\n",
      "--------------------\n",
      "train Loss: 0.0570 Img2Txt: 0.6612  Txt2Img: 0.6907\n",
      "test Loss: 0.1291 Img2Txt: 0.6612  Txt2Img: 0.6907\n",
      "Epoch 106/130\n",
      "--------------------\n",
      "train Loss: 0.0647 Img2Txt: 0.6598  Txt2Img: 0.6862\n",
      "test Loss: 0.1268 Img2Txt: 0.6598  Txt2Img: 0.6862\n",
      "Epoch 107/130\n",
      "--------------------\n",
      "train Loss: 0.0574 Img2Txt: 0.6890  Txt2Img: 0.6946\n",
      "test Loss: 0.1277 Img2Txt: 0.6890  Txt2Img: 0.6946\n",
      "Epoch 108/130\n",
      "--------------------\n",
      "train Loss: 0.0633 Img2Txt: 0.6669  Txt2Img: 0.6869\n",
      "test Loss: 0.1274 Img2Txt: 0.6669  Txt2Img: 0.6869\n",
      "Epoch 109/130\n",
      "--------------------\n",
      "train Loss: 0.0562 Img2Txt: 0.6741  Txt2Img: 0.6962\n",
      "test Loss: 0.1285 Img2Txt: 0.6741  Txt2Img: 0.6962\n",
      "Epoch 110/130\n",
      "--------------------\n",
      "train Loss: 0.0620 Img2Txt: 0.6591  Txt2Img: 0.6851\n",
      "test Loss: 0.1261 Img2Txt: 0.6591  Txt2Img: 0.6851\n",
      "Epoch 111/130\n",
      "--------------------\n",
      "train Loss: 0.0569 Img2Txt: 0.6914  Txt2Img: 0.7011\n",
      "test Loss: 0.1282 Img2Txt: 0.6914  Txt2Img: 0.7011\n",
      "Epoch 112/130\n",
      "--------------------\n",
      "train Loss: 0.0635 Img2Txt: 0.6833  Txt2Img: 0.6905\n",
      "test Loss: 0.1270 Img2Txt: 0.6833  Txt2Img: 0.6905\n",
      "Epoch 113/130\n",
      "--------------------\n",
      "train Loss: 0.0549 Img2Txt: 0.6717  Txt2Img: 0.6969\n",
      "test Loss: 0.1269 Img2Txt: 0.6717  Txt2Img: 0.6969\n",
      "Epoch 114/130\n",
      "--------------------\n",
      "train Loss: 0.0606 Img2Txt: 0.6645  Txt2Img: 0.6880\n",
      "test Loss: 0.1272 Img2Txt: 0.6645  Txt2Img: 0.6880\n",
      "Epoch 115/130\n",
      "--------------------\n",
      "train Loss: 0.0555 Img2Txt: 0.6866  Txt2Img: 0.6959\n",
      "test Loss: 0.1268 Img2Txt: 0.6866  Txt2Img: 0.6959\n",
      "Epoch 116/130\n",
      "--------------------\n",
      "train Loss: 0.0617 Img2Txt: 0.6542  Txt2Img: 0.6816\n",
      "test Loss: 0.1272 Img2Txt: 0.6542  Txt2Img: 0.6816\n",
      "Epoch 117/130\n",
      "--------------------\n",
      "train Loss: 0.0531 Img2Txt: 0.6726  Txt2Img: 0.6982\n",
      "test Loss: 0.1252 Img2Txt: 0.6726  Txt2Img: 0.6982\n",
      "Epoch 118/130\n",
      "--------------------\n",
      "train Loss: 0.0596 Img2Txt: 0.6601  Txt2Img: 0.6839\n",
      "test Loss: 0.1276 Img2Txt: 0.6601  Txt2Img: 0.6839\n",
      "Epoch 119/130\n",
      "--------------------\n",
      "train Loss: 0.0574 Img2Txt: 0.6763  Txt2Img: 0.6967\n",
      "test Loss: 0.1278 Img2Txt: 0.6763  Txt2Img: 0.6967\n",
      "Epoch 120/130\n",
      "--------------------\n",
      "train Loss: 0.0599 Img2Txt: 0.6662  Txt2Img: 0.6945\n",
      "test Loss: 0.1260 Img2Txt: 0.6662  Txt2Img: 0.6945\n",
      "Epoch 121/130\n",
      "--------------------\n",
      "train Loss: 0.0523 Img2Txt: 0.6770  Txt2Img: 0.6941\n",
      "test Loss: 0.1259 Img2Txt: 0.6770  Txt2Img: 0.6941\n",
      "Epoch 122/130\n",
      "--------------------\n",
      "train Loss: 0.0599 Img2Txt: 0.6569  Txt2Img: 0.6821\n",
      "test Loss: 0.1263 Img2Txt: 0.6569  Txt2Img: 0.6821\n",
      "Epoch 123/130\n",
      "--------------------\n",
      "train Loss: 0.0555 Img2Txt: 0.6874  Txt2Img: 0.6972\n",
      "test Loss: 0.1272 Img2Txt: 0.6874  Txt2Img: 0.6972\n",
      "Epoch 124/130\n",
      "--------------------\n",
      "train Loss: 0.0570 Img2Txt: 0.6628  Txt2Img: 0.6911\n",
      "test Loss: 0.1259 Img2Txt: 0.6628  Txt2Img: 0.6911\n",
      "Epoch 125/130\n",
      "--------------------\n",
      "train Loss: 0.0544 Img2Txt: 0.6862  Txt2Img: 0.6956\n",
      "test Loss: 0.1268 Img2Txt: 0.6862  Txt2Img: 0.6956\n",
      "Epoch 126/130\n",
      "--------------------\n",
      "train Loss: 0.0568 Img2Txt: 0.6605  Txt2Img: 0.6869\n",
      "test Loss: 0.1249 Img2Txt: 0.6605  Txt2Img: 0.6869\n",
      "Epoch 127/130\n",
      "--------------------\n",
      "train Loss: 0.0537 Img2Txt: 0.6821  Txt2Img: 0.6977\n",
      "test Loss: 0.1259 Img2Txt: 0.6821  Txt2Img: 0.6977\n",
      "Epoch 128/130\n",
      "--------------------\n",
      "train Loss: 0.0582 Img2Txt: 0.6748  Txt2Img: 0.6920\n",
      "test Loss: 0.1267 Img2Txt: 0.6748  Txt2Img: 0.6920\n",
      "Epoch 129/130\n",
      "--------------------\n",
      "train Loss: 0.0534 Img2Txt: 0.6873  Txt2Img: 0.6953\n",
      "test Loss: 0.1264 Img2Txt: 0.6873  Txt2Img: 0.6953\n",
      "Epoch 130/130\n",
      "--------------------\n",
      "train Loss: 0.0562 Img2Txt: 0.6666  Txt2Img: 0.6939\n",
      "test Loss: 0.1245 Img2Txt: 0.6666  Txt2Img: 0.6939\n",
      "Training complete in 0m 30s\n",
      "Best average ACC: 0.708495\n",
      "训练完成\n",
      "在测试集评估\n",
      "...Image to Text MAP = 0.6995274041965742\n",
      "...Text to Image MAP = 0.7174621056815108\n",
      "...Average MAP = 0.7084947549390426\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = 'pascal'\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_DIR =  dataset + '/'\n",
    "    MAX_EPOCH = 130\n",
    "    alpha = 1e-3\n",
    "    beta = 1\n",
    "    gamma=10\n",
    "    weight_decay = 0\n",
    "    batch_size = 100\n",
    "    lr = 1e-4\n",
    "    betas = (0.5, 0.999)\n",
    "    print('加载数据')\n",
    "\n",
    "    data_loader, input_data_par = get_loader(DATA_DIR, batch_size)\n",
    "\n",
    "    model_ft = IDCM_NN(img_input_dim=input_data_par['img_dim'], text_input_dim=input_data_par['text_dim'], output_dim=input_data_par['num_class']).to(device)\n",
    "    params_to_update = list(model_ft.parameters())\n",
    "    optimizer = optim.Adam(params_to_update, lr=lr, betas=betas,weight_decay=weight_decay)\n",
    "    print('开始训练')\n",
    "    model_ft, img_acc_hist, txt_acc_hist, loss_hist = train_model(model_ft, data_loader, optimizer, alpha, beta,gamma,MAX_EPOCH)\n",
    "    print('训练完成')\n",
    "    print('在测试集评估')\n",
    "    view1_feature, view2_feature, view1_predict, view2_predict = model_ft(torch.tensor(input_data_par['img_test']).to(device), torch.tensor(input_data_par['text_test']).to(device))\n",
    "    label = torch.argmax(torch.tensor(input_data_par['label_test']), dim=1)\n",
    "    view1_feature = view1_feature.detach().cpu().numpy()\n",
    "    view2_feature = view2_feature.detach().cpu().numpy()\n",
    "    view1_predict = view1_predict.detach().cpu().numpy()\n",
    "    view2_predict = view2_predict.detach().cpu().numpy()\n",
    "    img_to_txt = fx_calc_map_label(view1_feature, view2_feature, label)\n",
    "    print('...Image to Text MAP = {}'.format(img_to_txt))\n",
    "\n",
    "    txt_to_img = fx_calc_map_label(view2_feature, view1_feature, label)\n",
    "    print('...Text to Image MAP = {}'.format(txt_to_img))\n",
    "\n",
    "    print('...Average MAP = {}'.format(((img_to_txt + txt_to_img) / 2.)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T15:38:30.609696400Z",
     "start_time": "2023-12-18T15:38:00.295469400Z"
    }
   },
   "id": "3a28a4288cc8a8fb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "82f5fd8efdc03f8a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import copy\n",
    "origin = [1,2,[]]\n",
    "origin_1 = copy.copy(origin)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:07:58.620605200Z",
     "start_time": "2023-12-18T08:07:58.611327200Z"
    }
   },
   "id": "9c0ff4185b8fdb49"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:14:31.542428500Z",
     "start_time": "2023-12-18T08:14:31.540186700Z"
    }
   },
   "id": "c409fb389bd84c3b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "b[1]=0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:14:43.844980300Z",
     "start_time": "2023-12-18T08:14:43.837293600Z"
    }
   },
   "id": "f553440e8839474a"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "original_list = [1, [2, 3], 4]\n",
    "shallow_copy_list = copy.copy(original_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:18:40.260384600Z",
     "start_time": "2023-12-18T08:18:40.251192900Z"
    }
   },
   "id": "745b101aacabcb85"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "shallow_copy_list[2]=5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:18:40.761257400Z",
     "start_time": "2023-12-18T08:18:40.753228500Z"
    }
   },
   "id": "3740bfac4e3eed1a"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, [2, 3], 5]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_copy_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:18:44.710962300Z",
     "start_time": "2023-12-18T08:18:44.689470400Z"
    }
   },
   "id": "34a3820a9b9b1d28"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, [2, 3], 4]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:18:49.890885600Z",
     "start_time": "2023-12-18T08:18:49.881700800Z"
    }
   },
   "id": "e8c54b056d2128f5"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original List: [99, [999, 3], 4]\n",
      "Shallow Copy: [1, [999, 3], 4]\n",
      "Deep Copy: [1, [2, 3], 4]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# 原始列表\n",
    "original_list = [1, [2, 3], 4]\n",
    "\n",
    "# 浅拷贝\n",
    "shallow_copy_list = copy.copy(original_list)\n",
    "\n",
    "# 深拷贝\n",
    "deep_copy_list = copy.deepcopy(original_list)\n",
    "\n",
    "# 修改原始列表的第一个元素\n",
    "original_list[0] = 99\n",
    "\n",
    "# 修改原始列表中嵌套列表的第一个元素\n",
    "original_list[1][0] = 999\n",
    "\n",
    "# 输出结果\n",
    "print(\"Original List:\", original_list)\n",
    "print(\"Shallow Copy:\", shallow_copy_list)\n",
    "print(\"Deep Copy:\", deep_copy_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T08:24:21.842355900Z",
     "start_time": "2023-12-18T08:24:21.837799800Z"
    }
   },
   "id": "bb7e4a988f60a8b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
